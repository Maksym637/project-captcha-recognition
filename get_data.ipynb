{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"get_data.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMtBgFrDr9ViH4nNorLOcsD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8h73YAfmnGAn","executionInfo":{"status":"ok","timestamp":1661279319451,"user_tz":-180,"elapsed":54487,"user":{"displayName":"Максим Олійник","userId":"04464289889461830059"}},"outputId":"a5d3326d-676b-4054-d580-2ec7fd9ff10f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["%cd /content/drive/MyDrive"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"77CVMbNonbf-","executionInfo":{"status":"ok","timestamp":1661279333498,"user_tz":-180,"elapsed":277,"user":{"displayName":"Максим Олійник","userId":"04464289889461830059"}},"outputId":"f04708a0-2c29-47f5-bcfa-57a50000a5d6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive\n"]}]},{"cell_type":"code","source":["# !unzip '/content/drive/MyDrive/archive.zip' -d '/content'"],"metadata":{"id":"8vUddg1gkllG","executionInfo":{"status":"ok","timestamp":1661293913904,"user_tz":-180,"elapsed":20,"user":{"displayName":"Максим Олійник","userId":"04464289889461830059"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["import os\n","from pathlib import Path\n","from google.colab.patches import cv2_imshow\n","\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","from tensorflow import keras"],"metadata":{"id":"oaLp6gKe6eXj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Loading the Data"],"metadata":{"id":"nCWHoCtxxju8"}},{"cell_type":"code","source":["BATCH_SIZE = 64\n","IMG_WIDTH = 200\n","IMG_HEIGHT = 50"],"metadata":{"id":"1u3AeFkfL3GJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_dir = Path('/content/images_before_edit/')\n","\n","# downloading all images and converting them into list\n","images = sorted(list(map(str, list(data_dir.glob(\"*.png\")))))\n","\n","# getting all labels of images\n","labels = [img.split(os.path.sep)[-1].split(\".png\")[0] for img in images]\n","\n","# getting all characters from labels\n","characters = set(char for label in labels for char in label)"],"metadata":{"id":"QllasaHS0j4J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(images), len(labels))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NNtc8nFLSNTv","executionInfo":{"status":"ok","timestamp":1661279375601,"user_tz":-180,"elapsed":318,"user":{"displayName":"Максим Олійник","userId":"04464289889461830059"}},"outputId":"e6abb5ff-1b67-4633-9c47-d4405e3b5efe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["64961 64961\n"]}]},{"cell_type":"markdown","source":["### All characters for image names"],"metadata":{"id":"6pB1h5hATihk"}},{"cell_type":"code","source":["# print all information about characters\n","digits = sorted(characters)[:10]\n","letters = sorted(characters)[10:]\n","\n","print(f\"Digits : {digits}\")\n","print(f\"Letters : {letters}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5wMe2lg1SnBc","executionInfo":{"status":"ok","timestamp":1661279377478,"user_tz":-180,"elapsed":288,"user":{"displayName":"Максим Олійник","userId":"04464289889461830059"}},"outputId":"c89452f9-816d-4f6b-c9a8-af2885769ceb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Digits : ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n","Letters : ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"]}]},{"cell_type":"markdown","source":["### Spliting the Data\n","- Train Dataset : 80 %\n","- Validation Dataset : 10 %\n","- Test Dataset : 10 %"],"metadata":{"id":"xn3doOMrUY0S"}},{"cell_type":"code","source":["# converting a characters into number \n","char_to_num = keras.layers.StringLookup(\n","    vocabulary=list(characters), mask_token=None\n",")\n","\n","\n","# converting vice versa\n","num_to_char = keras.layers.StringLookup(\n","    vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True\n",")\n","\n","\n","# data distribution\n","def split_data(images, labels, train_size=0.8, shuffle=True):\n","    size = len(images)\n","\n","    # data shuffling\n","    indices = np.arange(size)\n","    if shuffle:\n","        np.random.shuffle(indices)\n","\n","    samples_80 = int(len(images) * train_size)\n","    samples_90 = int(len(images) * (train_size + (1 - train_size) / 2))\n","\n","    x_train, y_train = images[indices[:samples_80]], labels[indices[:samples_80]]\n","    x_valid, y_valid = images[indices[samples_80:samples_90]], labels[indices[samples_80:samples_90]]\n","    x_test, y_test = images[indices[samples_90:]], labels[indices[samples_90:]]\n","\n","    return x_train, x_valid, x_test, y_train, y_valid, y_test\n","\n","\n","x_train, x_valid, x_test, y_train, y_valid, y_test = split_data(np.array(images), np.array(labels))\n","\n","\n","# function for image processing and\n","# for label encoding to 'utf-8'\n","def encode_single_sample(img_path, label):\n","    img = tf.io.read_file(img_path)\n","    img = tf.io.decode_png(img, channels=1)\n","\n","    img = tf.image.convert_image_dtype(img, tf.float32)\n","\n","    img = tf.image.resize(img, [IMG_HEIGHT, IMG_WIDTH])\n","    img = tf.transpose(img, perm=[1, 0, 2])\n","\n","    # img /= 255.0 --> normalization\n","\n","    label = char_to_num(tf.strings.unicode_split(label, input_encoding=\"UTF-8\"))\n","\n","    return {\"image\": img, \"label\": label}"],"metadata":{"id":"WZe2Nvc_UgAn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Data manipulation with _.from_tensor_slices(...)_"],"metadata":{"id":"dh2AhxX_U5qJ"}},{"cell_type":"code","source":["train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n","\n","train_dataset = (\n","    train_dataset.map(\n","        encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE\n","    )\n","    .batch(BATCH_SIZE)\n","    .prefetch(8) # buffer_size=tf.data.AUTOTUNE\n",")\n","\n","validation_dataset = tf.data.Dataset.from_tensor_slices((x_valid, y_valid))\n","\n","validation_dataset = (\n","    validation_dataset.map(\n","        encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE\n","    )\n","    .batch(BATCH_SIZE)\n","    .prefetch(8) # buffer_size=tf.data.AUTOTUNE\n",")"],"metadata":{"id":"CAsh4aIkVM09"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Data visualization"],"metadata":{"id":"TE9uTzwQaYtS"}},{"cell_type":"code","source":["# fig, ax = plt.subplots(4, 4, figsize=(20, 10))\n","\n","# for batch in train_dataset.take(1):\n","#     images = batch[\"image\"]\n","#     labels = batch[\"label\"]\n","#     for i in range(16):\n","#         img = (images[i] * 255).numpy().astype(\"uint8\")\n","#         label = tf.strings.reduce_join(num_to_char(labels[i])).numpy().decode(\"utf-8\")\n","#         ax[i // 4, i % 4].imshow(img[:, :, 0].T, cmap=\"gray\")\n","#         ax[i // 4, i % 4].set_title(label)\n","#         ax[i // 4, i % 4].axis(\"off\")\n","\n","# plt.show()"],"metadata":{"id":"nd132DFRava_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### OCR Model **CRNN** with **CTC-loss-function**"],"metadata":{"id":"3RHhabRFdMpk"}},{"cell_type":"code","source":["class CTCLayer(keras.layers.Layer):\n","    def __init__(self, name=None):\n","        super().__init__(name=name)\n","        self.loss_fn = keras.backend.ctc_batch_cost\n","\n","    def call(self, y_true, y_pred):\n","        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n","        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n","        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n","\n","        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n","        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n","\n","        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n","        self.add_loss(loss)\n","\n","        return y_pred\n","\n","\n","def build_model():\n","    input_img = keras.layers.Input(\n","        shape=(IMG_WIDTH, IMG_HEIGHT, 1), name=\"image\", dtype=\"float32\"\n","    )\n","    labels = keras.layers.Input(name=\"label\", shape=(None,), dtype=\"float32\")\n","\n","    # 1 Conv2D()\n","    x = keras.layers.Conv2D(\n","        32,\n","        (3, 3),\n","        activation=\"relu\",\n","        kernel_initializer=\"he_normal\",\n","        padding=\"same\",\n","        name=\"Conv1\",\n","    )(input_img)\n","    x = keras.layers.MaxPooling2D((2, 2), name=\"pool1\")(x)\n","\n","    # 2 Conv2D()\n","    x = keras.layers.Conv2D(\n","        64,\n","        (3, 3),\n","        activation=\"relu\",\n","        kernel_initializer=\"he_normal\",\n","        padding=\"same\",\n","        name=\"Conv2\",\n","    )(x)\n","    x = keras.layers.MaxPooling2D((2, 2), name=\"pool2\")(x)\n","    \n","    new_shape = ((IMG_WIDTH // 4), (IMG_HEIGHT // 4) * 64)\n","    x = keras.layers.Reshape(target_shape=new_shape, name=\"reshape\")(x)\n","    x = keras.layers.Dense(64, activation=\"relu\", name=\"dense1\")(x)\n","    x = keras.layers.Dropout(0.2)(x)\n","\n","    # RNNs\n","    x = keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True, dropout=0.25))(x)\n","    x = keras.layers.Bidirectional(keras.layers.LSTM(64, return_sequences=True, dropout=0.25))(x)\n","\n","    x = keras.layers.Dense(\n","        len(char_to_num.get_vocabulary()) + 1, activation=\"softmax\", name=\"dense2\"\n","    )(x)\n","\n","    output = CTCLayer(name=\"ctc_loss\")(labels, x)\n","\n","    model = keras.models.Model(\n","        inputs=[input_img, labels], outputs=output, name=\"ocr_model_v1\"\n","    )\n","\n","    opt = keras.optimizers.Adam()\n","    model.compile(optimizer=opt)\n","\n","    return model"],"metadata":{"id":"M2d9KwmLdQh7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = build_model()\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EeVt9kZWdvDG","executionInfo":{"status":"ok","timestamp":1661279394722,"user_tz":-180,"elapsed":1966,"user":{"displayName":"Максим Олійник","userId":"04464289889461830059"}},"outputId":"5140d69f-7229-4d48-b98a-6e99495c32da"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"ocr_model_v1\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," image (InputLayer)             [(None, 200, 50, 1)  0           []                               \n","                                ]                                                                 \n","                                                                                                  \n"," Conv1 (Conv2D)                 (None, 200, 50, 32)  320         ['image[0][0]']                  \n","                                                                                                  \n"," pool1 (MaxPooling2D)           (None, 100, 25, 32)  0           ['Conv1[0][0]']                  \n","                                                                                                  \n"," Conv2 (Conv2D)                 (None, 100, 25, 64)  18496       ['pool1[0][0]']                  \n","                                                                                                  \n"," pool2 (MaxPooling2D)           (None, 50, 12, 64)   0           ['Conv2[0][0]']                  \n","                                                                                                  \n"," reshape (Reshape)              (None, 50, 768)      0           ['pool2[0][0]']                  \n","                                                                                                  \n"," dense1 (Dense)                 (None, 50, 64)       49216       ['reshape[0][0]']                \n","                                                                                                  \n"," dropout (Dropout)              (None, 50, 64)       0           ['dense1[0][0]']                 \n","                                                                                                  \n"," bidirectional (Bidirectional)  (None, 50, 256)      197632      ['dropout[0][0]']                \n","                                                                                                  \n"," bidirectional_1 (Bidirectional  (None, 50, 128)     164352      ['bidirectional[0][0]']          \n"," )                                                                                                \n","                                                                                                  \n"," label (InputLayer)             [(None, None)]       0           []                               \n","                                                                                                  \n"," dense2 (Dense)                 (None, 50, 38)       4902        ['bidirectional_1[0][0]']        \n","                                                                                                  \n"," ctc_loss (CTCLayer)            (None, 50, 38)       0           ['label[0][0]',                  \n","                                                                  'dense2[0][0]']                 \n","                                                                                                  \n","==================================================================================================\n","Total params: 434,918\n","Trainable params: 434,918\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["epochs = 100"],"metadata":{"id":"JGWcZXjXDihN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = model.fit(train_dataset, validation_data=validation_dataset, epochs=epochs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xEtVrH02DkTC","outputId":"e7446b3b-0c51-4e52-b855-265f0b8c255d","executionInfo":{"status":"ok","timestamp":1661293180008,"user_tz":-180,"elapsed":13776987,"user":{"displayName":"Максим Олійник","userId":"04464289889461830059"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","812/812 [==============================] - 107s 108ms/step - loss: 23.4113 - val_loss: 22.5245\n","Epoch 2/100\n","812/812 [==============================] - 88s 109ms/step - loss: 22.2756 - val_loss: 21.9290\n","Epoch 3/100\n","812/812 [==============================] - 95s 117ms/step - loss: 21.3114 - val_loss: 19.7272\n","Epoch 4/100\n","812/812 [==============================] - 87s 107ms/step - loss: 18.2829 - val_loss: 16.2619\n","Epoch 5/100\n","812/812 [==============================] - 85s 104ms/step - loss: 14.9497 - val_loss: 12.4283\n","Epoch 6/100\n","812/812 [==============================] - 85s 105ms/step - loss: 11.5821 - val_loss: 7.6916\n","Epoch 7/100\n","812/812 [==============================] - 86s 106ms/step - loss: 7.0678 - val_loss: 4.7721\n","Epoch 8/100\n","812/812 [==============================] - 87s 107ms/step - loss: 5.0268 - val_loss: 3.0728\n","Epoch 9/100\n","812/812 [==============================] - 87s 107ms/step - loss: 3.6763 - val_loss: 2.1160\n","Epoch 10/100\n","812/812 [==============================] - 88s 109ms/step - loss: 2.8016 - val_loss: 1.5317\n","Epoch 11/100\n","812/812 [==============================] - 86s 106ms/step - loss: 2.2821 - val_loss: 1.1846\n","Epoch 12/100\n","812/812 [==============================] - 86s 106ms/step - loss: 1.8533 - val_loss: 0.9185\n","Epoch 13/100\n","812/812 [==============================] - 85s 105ms/step - loss: 1.5510 - val_loss: 0.6863\n","Epoch 14/100\n","812/812 [==============================] - 85s 104ms/step - loss: 1.3050 - val_loss: 0.5479\n","Epoch 15/100\n","812/812 [==============================] - 87s 107ms/step - loss: 1.1544 - val_loss: 0.4811\n","Epoch 16/100\n","812/812 [==============================] - 85s 105ms/step - loss: 0.9746 - val_loss: 0.3172\n","Epoch 17/100\n","812/812 [==============================] - 86s 106ms/step - loss: 0.8214 - val_loss: 0.3067\n","Epoch 18/100\n","812/812 [==============================] - 86s 106ms/step - loss: 0.7646 - val_loss: 0.2934\n","Epoch 19/100\n","812/812 [==============================] - 86s 106ms/step - loss: 0.6844 - val_loss: 0.2832\n","Epoch 20/100\n","812/812 [==============================] - 86s 106ms/step - loss: 0.6548 - val_loss: 0.2516\n","Epoch 21/100\n","812/812 [==============================] - 84s 104ms/step - loss: 0.6594 - val_loss: 0.2138\n","Epoch 22/100\n","812/812 [==============================] - 88s 108ms/step - loss: 0.5900 - val_loss: 0.2503\n","Epoch 23/100\n","812/812 [==============================] - 88s 108ms/step - loss: 0.5595 - val_loss: 0.1769\n","Epoch 24/100\n","812/812 [==============================] - 86s 106ms/step - loss: 0.5344 - val_loss: 0.1998\n","Epoch 25/100\n","812/812 [==============================] - 102s 125ms/step - loss: 0.5260 - val_loss: 0.1694\n","Epoch 26/100\n","812/812 [==============================] - 88s 108ms/step - loss: 0.5119 - val_loss: 0.1790\n","Epoch 27/100\n","812/812 [==============================] - 94s 116ms/step - loss: 0.5060 - val_loss: 0.1744\n","Epoch 28/100\n","812/812 [==============================] - 87s 107ms/step - loss: 0.6028 - val_loss: 0.1587\n","Epoch 29/100\n","812/812 [==============================] - 85s 104ms/step - loss: 0.4399 - val_loss: 0.1774\n","Epoch 30/100\n","812/812 [==============================] - 90s 111ms/step - loss: 0.4916 - val_loss: 0.1875\n","Epoch 31/100\n","812/812 [==============================] - 96s 118ms/step - loss: 0.3942 - val_loss: 0.1860\n","Epoch 32/100\n","812/812 [==============================] - 89s 109ms/step - loss: 0.4393 - val_loss: 0.1551\n","Epoch 33/100\n","812/812 [==============================] - 94s 115ms/step - loss: 0.4038 - val_loss: 0.1480\n","Epoch 34/100\n","812/812 [==============================] - 93s 115ms/step - loss: 0.3861 - val_loss: 0.1738\n","Epoch 35/100\n","812/812 [==============================] - 92s 114ms/step - loss: 0.4612 - val_loss: 0.3507\n","Epoch 36/100\n","812/812 [==============================] - 88s 108ms/step - loss: 0.4289 - val_loss: 0.1387\n","Epoch 37/100\n","812/812 [==============================] - 91s 112ms/step - loss: 0.3448 - val_loss: 0.1525\n","Epoch 38/100\n","812/812 [==============================] - 91s 112ms/step - loss: 0.3755 - val_loss: 0.1469\n","Epoch 39/100\n","812/812 [==============================] - 88s 109ms/step - loss: 0.3298 - val_loss: 0.1226\n","Epoch 40/100\n","812/812 [==============================] - 88s 108ms/step - loss: 0.3661 - val_loss: 0.1272\n","Epoch 41/100\n","812/812 [==============================] - 89s 109ms/step - loss: 0.3839 - val_loss: 0.1220\n","Epoch 42/100\n","812/812 [==============================] - 89s 110ms/step - loss: 1.9254 - val_loss: 0.3398\n","Epoch 43/100\n","812/812 [==============================] - 88s 108ms/step - loss: 0.5466 - val_loss: 0.1046\n","Epoch 44/100\n","812/812 [==============================] - 90s 111ms/step - loss: 0.2784 - val_loss: 0.0811\n","Epoch 45/100\n","812/812 [==============================] - 88s 109ms/step - loss: 0.2086 - val_loss: 0.0733\n","Epoch 46/100\n","812/812 [==============================] - 89s 110ms/step - loss: 0.1790 - val_loss: 0.0648\n","Epoch 47/100\n","812/812 [==============================] - 89s 109ms/step - loss: 0.1578 - val_loss: 0.0591\n","Epoch 48/100\n","812/812 [==============================] - 88s 108ms/step - loss: 0.1416 - val_loss: 0.0598\n","Epoch 49/100\n","812/812 [==============================] - 88s 109ms/step - loss: 0.1359 - val_loss: 0.0583\n","Epoch 50/100\n","812/812 [==============================] - 86s 106ms/step - loss: 0.1296 - val_loss: 0.0590\n","Epoch 51/100\n","812/812 [==============================] - 88s 109ms/step - loss: 0.1298 - val_loss: 0.0701\n","Epoch 52/100\n","812/812 [==============================] - 86s 106ms/step - loss: 0.1197 - val_loss: 0.0666\n","Epoch 53/100\n","812/812 [==============================] - 88s 108ms/step - loss: 0.1221 - val_loss: 0.0590\n","Epoch 54/100\n","812/812 [==============================] - 88s 108ms/step - loss: 0.1124 - val_loss: 0.0631\n","Epoch 55/100\n","812/812 [==============================] - 87s 108ms/step - loss: 0.1108 - val_loss: 0.0711\n","Epoch 56/100\n","812/812 [==============================] - 87s 107ms/step - loss: 0.1082 - val_loss: 0.0523\n","Epoch 57/100\n","812/812 [==============================] - 87s 107ms/step - loss: 0.1038 - val_loss: 0.0443\n","Epoch 58/100\n","812/812 [==============================] - 87s 107ms/step - loss: 0.0970 - val_loss: 0.0492\n","Epoch 59/100\n","812/812 [==============================] - 90s 110ms/step - loss: 0.1007 - val_loss: 0.0476\n","Epoch 60/100\n","812/812 [==============================] - 91s 112ms/step - loss: 0.0929 - val_loss: 0.0461\n","Epoch 61/100\n","812/812 [==============================] - 89s 110ms/step - loss: 0.0875 - val_loss: 0.0466\n","Epoch 62/100\n","812/812 [==============================] - 93s 114ms/step - loss: 0.0911 - val_loss: 0.0547\n","Epoch 63/100\n","812/812 [==============================] - 89s 109ms/step - loss: 0.0833 - val_loss: 0.0497\n","Epoch 64/100\n","812/812 [==============================] - 87s 107ms/step - loss: 0.0833 - val_loss: 0.0455\n","Epoch 65/100\n","812/812 [==============================] - 87s 107ms/step - loss: 0.0872 - val_loss: 0.0540\n","Epoch 66/100\n","812/812 [==============================] - 86s 106ms/step - loss: 0.0755 - val_loss: 0.0461\n","Epoch 67/100\n","812/812 [==============================] - 87s 107ms/step - loss: 0.0782 - val_loss: 0.0470\n","Epoch 68/100\n","812/812 [==============================] - 87s 107ms/step - loss: 0.0762 - val_loss: 0.0425\n","Epoch 69/100\n","812/812 [==============================] - 89s 110ms/step - loss: 0.0765 - val_loss: 0.0473\n","Epoch 70/100\n","812/812 [==============================] - 88s 108ms/step - loss: 0.0716 - val_loss: 0.0430\n","Epoch 71/100\n","812/812 [==============================] - 88s 109ms/step - loss: 0.0702 - val_loss: 0.0486\n","Epoch 72/100\n","812/812 [==============================] - 86s 106ms/step - loss: 0.0680 - val_loss: 0.0505\n","Epoch 73/100\n","812/812 [==============================] - 88s 109ms/step - loss: 0.0696 - val_loss: 0.0497\n","Epoch 74/100\n","812/812 [==============================] - 89s 110ms/step - loss: 0.0672 - val_loss: 0.0428\n","Epoch 75/100\n","812/812 [==============================] - 93s 114ms/step - loss: 0.0663 - val_loss: 0.0496\n","Epoch 76/100\n","812/812 [==============================] - 90s 111ms/step - loss: 0.0628 - val_loss: 0.0482\n","Epoch 77/100\n","812/812 [==============================] - 90s 111ms/step - loss: 0.0717 - val_loss: 0.0541\n","Epoch 78/100\n","812/812 [==============================] - 88s 109ms/step - loss: 0.0623 - val_loss: 0.0508\n","Epoch 79/100\n","812/812 [==============================] - 92s 113ms/step - loss: 0.0678 - val_loss: 0.0482\n","Epoch 80/100\n","812/812 [==============================] - 91s 112ms/step - loss: 0.0636 - val_loss: 0.0460\n","Epoch 81/100\n","812/812 [==============================] - 94s 115ms/step - loss: 0.0620 - val_loss: 0.0506\n","Epoch 82/100\n","812/812 [==============================] - 88s 108ms/step - loss: 0.0547 - val_loss: 0.0525\n","Epoch 83/100\n","812/812 [==============================] - 88s 109ms/step - loss: 0.0592 - val_loss: 0.0564\n","Epoch 84/100\n","812/812 [==============================] - 86s 106ms/step - loss: 0.0603 - val_loss: 0.0552\n","Epoch 85/100\n","812/812 [==============================] - 89s 109ms/step - loss: 0.0582 - val_loss: 0.0568\n","Epoch 86/100\n","812/812 [==============================] - 89s 110ms/step - loss: 0.0597 - val_loss: 0.0500\n","Epoch 87/100\n","812/812 [==============================] - 89s 110ms/step - loss: 0.0576 - val_loss: 0.0491\n","Epoch 88/100\n","812/812 [==============================] - 89s 110ms/step - loss: 0.0570 - val_loss: 0.0475\n","Epoch 89/100\n","812/812 [==============================] - 89s 109ms/step - loss: 0.0574 - val_loss: 0.0563\n","Epoch 90/100\n","812/812 [==============================] - 89s 110ms/step - loss: 0.0568 - val_loss: 0.0584\n","Epoch 91/100\n","812/812 [==============================] - 87s 107ms/step - loss: 0.0564 - val_loss: 0.0720\n","Epoch 92/100\n","812/812 [==============================] - 90s 111ms/step - loss: 0.0547 - val_loss: 0.0500\n","Epoch 93/100\n","812/812 [==============================] - 89s 110ms/step - loss: 0.0550 - val_loss: 0.0472\n","Epoch 94/100\n","812/812 [==============================] - 91s 112ms/step - loss: 0.0512 - val_loss: 0.0467\n","Epoch 95/100\n","812/812 [==============================] - 89s 110ms/step - loss: 0.0525 - val_loss: 0.0470\n","Epoch 96/100\n","812/812 [==============================] - 89s 110ms/step - loss: 0.0541 - val_loss: 0.0512\n","Epoch 97/100\n","812/812 [==============================] - 88s 108ms/step - loss: 0.0520 - val_loss: 0.0495\n","Epoch 98/100\n","812/812 [==============================] - 87s 108ms/step - loss: 0.0534 - val_loss: 0.0435\n","Epoch 99/100\n","812/812 [==============================] - 86s 106ms/step - loss: 0.0477 - val_loss: 0.0488\n","Epoch 100/100\n","812/812 [==============================] - 87s 107ms/step - loss: 0.0502 - val_loss: 0.0498\n"]}]},{"cell_type":"code","source":["tf.saved_model.save(model, '/contenct/drive/MyDrive/project-captcha-recognition')"],"metadata":{"id":"WcHMaPVgzooI"},"execution_count":null,"outputs":[]}]}